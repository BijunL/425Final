{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Choice of F1 Score\n",
        "\n",
        "在处理不平衡类别数据集时，选择合适的评估指标非常关键。相比于精确度（Accuracy），F1分数是更合适的度量标准，尤其是当数据集中的类别分布极不均衡时。下面是对F1分数及其重要性的详细解释。\n",
        "\n",
        "F1 分数是精确度（Precision）和召回率（Recall）的调和平均值，公式如下：\n",
        "\n",
        "$$\n",
        "F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "$$\n",
        "\n",
        "- **精确度（Precision）**关注于被正确识别为正类的比例。\n",
        "- **召回率（Recall）**强调的是实际正类被正确识别的比例。\n",
        "\n",
        "### F1 分数的重要性\n",
        "\n",
        "- 当分类器错误地预测少数类（负类），即假正例（False Positives）增加时，精确度会降低，从而导致F1分数降低。\n",
        "- 另一方面，如果分类器对少数类的识别能力较差，即错误地将多数类预测为少数类（假负例，False Negatives）增加时，召回率和F1分数也会降低。\n",
        "- 总的来说，**F1分数只有在预测的数量和质量同时提高时才会增加**。\n",
        "- 在Imbalanced的数据集场景中，F1分数比单独的精确度或召回率更为合适，因为它综合了这两者的平衡。这在预测多数类时可能具有高精确度但未能有效捕获少数类，或者相反情况的模型中尤为重要。\n",
        "\n",
        "### F1 分数在关键应用中的价值\n",
        "\n",
        "F1分数有助于识别那些在正确识别正类的同时，最小化假正例的模型，这在如医疗诊断等关键应用中尤为重要。它为我们提供了一个在不平衡数据集中评估模型性能的有效工具，确保我们的模型不仅能够准确预测，而且能够全面捕获所有相关的正类案例。"
      ],
      "metadata": {
        "id": "iq-jAB-WX-we"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resampling methods 重采样方法\n",
        "\n",
        "在机器学习和统计学中，重采样方法是解决数据不平衡问题的一种基本方法。当数据集中某一类别的样本数量远少于其他类别时，就会出现类别不平衡的问题，这可能会对模型的学习和泛化能力造成不利影响。重采样方法旨在通过改变数据集的组成来使类别分布更加均衡。以下是重采样方法的详细介绍：\n",
        "\n",
        "### 数据中心AI与算法中心AI\n",
        "\n",
        "- **数据中心AI**（Data-centric AI）关注于改善和优化数据质量，包括数据的收集、清洗、增强和重采样，以提高AI系统的性能。\n",
        "- **算法中心AI**（Algorithm-centric AI）则侧重于开发和优化算法，以提高模型的表现。\n",
        "\n",
        "在处理不平衡数据集时，采用数据中心AI的方法，如重采样，可以显著提高模型的表现。\n",
        "\n",
        "### 重采样方法类型\n",
        "\n",
        "1. **过采样少数类（Oversampling the Minority Class）**：\n",
        "   - 过采样是指在数据集中增加少数类样本的数量，以解决类别不平衡问题。这可以通过简单复制少数类样本或者使用更复杂的技术如SMOTE（合成少数类过采样技术）来实现，后者通过在少数类样本之间插值来生成新样本。\n",
        "\n",
        "2. **欠采样多数类（Undersampling the Majority Class）**：\n",
        "   - 欠采样是指减少多数类样本的数量，以达到更均衡的类别分布。这种方法在多数类样本数量非常多时特别有用，但它可能会导致信息损失，因为一些多数类样本将不被模型学习。\n",
        "\n",
        "### 重采样方法的应用\n",
        "\n",
        "- 在应用重采样方法时，需要谨慎选择合适的技术，以确保数据的代表性和多样性不会被损害。\n",
        "- 过采样少数类可能导致过拟合，因为模型可能会对重复的少数类样本过于敏感。\n",
        "- 欠采样多数类可能导致欠拟合，因为移除了一部分多数类的信息。\n",
        "\n",
        "因此，在实际应用中，可能需要结合多种技术，甚至考虑使用更先进的重采样方法，如集成方法，来更好地处理不平衡数据问题。重采样方法的选择和应用需要根据具体的数据集和任务需求进行调整，以达到最佳的模型性能。\n",
        "\n"
      ],
      "metadata": {
        "id": "kgoZG3pLYjnD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SMOTE 合成少数过采样技术\n",
        "\n",
        "合成少数过采样技术（SMOTE）是一种高级的过采样方法，旨在通过生成合成样本而非简单复制已有的少数类样本来解决不平衡数据问题。下面详细解释SMOTE及其变体和相关技术。\n",
        "\n",
        "- SMOTE通过以下步骤生成新的合成少数类样本：\n",
        "  1. 从少数类中随机选择一个样本，记为 $O$（原点）。\n",
        "  2. 找到 $O$ 的 $K$ 个最近邻居，这些邻居同属于少数类。\n",
        "  3. 用直线连接 $O$ 和它的每一个邻居。\n",
        "  4. 在每条连线上，根据随机选择的缩放因子 $z$（在[0,1]范围内），在 $O$ 和邻居之间的连线上随机生成新的点。这些新点作为合成的样本。\n",
        "  5. 重复这个过程直到生成所需数量的合成样本。\n",
        "\n",
        "### 传统SMOTE的弱点\n",
        "\n",
        "- 如果步骤1或步骤2中选取的点位于由多数类样本主导的区域，那么生成的合成点可能会落在多数类区域内，这可能会使分类变得困难。\n",
        "\n",
        "### 边界SMOTE（Borderline SMOTE）\n",
        "\n",
        "- 为了克服传统SMOTE的局限性，边界SMOTE方法识别出两类点——“噪声”点和“边界”点。\n",
        "  - “噪声”点是指所有最近邻居都属于不同类别（即多数类）的点。\n",
        "  - “边界”点是指最近邻居中既有多数类点也有少数类点的点。\n",
        "- 在边界SMOTE中，选择“边界”点作为 $O$ 点，生成新点时放宽选择同类最近邻的标准，允许选择不同类的点，以更接近分类边界生成新的样本。\n",
        "\n",
        "### K-Means SMOTE\n",
        "\n",
        "- K均值SMOTE是一种较新的方法，旨在减少其他过采样方法可能产生的噪声合成点。它的工作原理如下：\n",
        "  1. 对数据进行K均值聚类。\n",
        "  2. 选择那些少数类样本比例较高（>50%或用户定义）的聚类。\n",
        "  3. 对这些选定的聚类应用传统SMOTE，为每个聚类生成新的合成点。\n",
        "\n",
        "- 在K均值SMOTE中，聚类旨在将相似的数据点分组到 $k$ 个聚类中，通过最小化每个聚类内的方差并最大化聚类间的方差来进行。新的少数类样本将被分配到不会使其变成多数的聚类中，以避免过度稠密或过于稀疏，从而更好地反映少数类的分布。\n",
        "\n",
        "SMOTE及其变体提供了处理不平衡数据集的有效手段，通过生成合成的少数类样本来增强模型的学习能力。然而，在应用这些技术时也需注意其局限性，如在选择合适的K值时的挑战，并结合具体的数据集特性和任务需求来灵活运用。"
      ],
      "metadata": {
        "id": "-QrwtWAXZkFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SMOTE Example\n",
        "from random import randrange, uniform  # 导入随机库中的函数，用于生成随机数\n",
        "from sklearn.neighbors import NearestNeighbors  # 从sklearn库中导入最近邻算法\n",
        "import numpy as np  # 导入NumPy库，用于数值计算\n",
        "import pandas as pd  # 导入Pandas库，用于数据处理\n",
        "from sklearn.ensemble import RandomForestClassifier  # 从sklearn库中导入随机森林分类器\n",
        "from sklearn.model_selection import train_test_split  # 导入数据拆分函数，用于创建训练集和测试集\n",
        "from sklearn.metrics import confusion_matrix, recall_score  # 导入性能评估工具\n",
        "\n",
        "# 读取数据\n",
        "df = pd.read_csv(\"creditcard.csv\")  # 使用Pandas读取CSV文件中的信用卡交易数据\n",
        "\n",
        "# 数据说明\n",
        "# 由于保密性问题，原始特征未提供。\n",
        "# V1到V28是通过PCA获得的主成分，唯一未经PCA转换的特征是‘Time’和‘Amount’。\n",
        "\n",
        "# 检查类别分布\n",
        "df['Class'].value_counts()  # 查看类别分布，比较正样本（欺诈）和负样本（非欺诈）的数量\n",
        "\n",
        "# 简化数据集\n",
        "df = df.drop(['Time'], axis=1)  # 删除‘Time’列，因为我们在这里不考虑时间维度\n",
        "\n",
        "# 分离特征和标签\n",
        "X = df.drop(['Class'], axis=1)  # 分离特征，即除去标签列的所有列\n",
        "y = df['Class']  # 分离标签，即‘Class’列\n",
        "\n",
        "# # 将数据拆分为训练集和测试集，测试集占20%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# 初始化随机森林分类器，# 创建随机森林分类器实例，设置随机种子42以保证结果的可重复性\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# 训练模型\n",
        "rf.fit(X_train, y_train)  # 使用训练集数据训练随机森林模型\n",
        "\n",
        "# 进行预测\n",
        "y_pred = rf.predict(X_test)  # 使用训练好的模型对测试集进行预测\n",
        "\n",
        "# 评估模型性能\n",
        "# 在未实现SMOTE的情况下，以下是评估模型性能的混淆矩阵\n",
        "# 可以看到，模型将23个样本错误地分类为非欺诈\n",
        "confusion_matrix(y_test, y_pred)  # 使用混淆矩阵来评估模型性能\n"
      ],
      "metadata": {
        "id": "EugVoFJWesuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SMOTE using library\n",
        "\n",
        "# 安装SMOTE库\n",
        "# 需要在命令行中执行: pip install imbalanced-learn\n",
        "\n",
        "# 从imblearn库导入SMOTE类，用于过采样少数类\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# 重新读取数据\n",
        "df = pd.read_csv(\"creditcard.csv\")  # 使用pandas重新读取信用卡数据集\n",
        "df = df.drop(['Time'], axis=1)  # 删除'Time'列，因为我们不考虑时间因素\n",
        "\n",
        "# 分离特征和标签\n",
        "X = df.drop(['Class'], axis=1)  # 分离出特征，即除去标签列'Class'的所有列\n",
        "y = df['Class']  # 分离出标签，即'Class'列\n",
        "\n",
        "# 创建SMOTE实例\n",
        "# 实例化SMOTE类，设置随机种子以确保可重复性，k_neighbors设置为5\n",
        "sm = SMOTE(random_state=42, k_neighbors=5)\n",
        "\n",
        "# 应用SMOTE算法，生成新的重采样后的特征集X_res和标签集y_res\n",
        "X_res, y_res = sm.fit_resample(X, y)\n",
        "\n",
        "# # 将重采样后的数据集分割为训练集和测试集\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2,\n",
        "                                                    random_state=42)\n",
        "# 初始化并训练随机森林模型\n",
        "rf = RandomForestClassifier(random_state=42)  # 创建随机森林分类器实例\n",
        "rf.fit(X_train, y_train)  # 使用训练集训练模型\n",
        "\n",
        "#  使用训练好的模型对测试集进行预测\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# 使用Confusion Matrix评估模型性能\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "Jf7cryWifnA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Empirical comparison of different approaches to deal with imbalanced data\n",
        "\n",
        "在处理不平衡数据时，常见的策略包括欠采样（Undersampling）、过采样（Oversampling）和SMOTE（合成少数过采样技术）。通过一项实证比较，我们可以深入了解这些方法在教育数据挖掘中处理不平衡分类问题的有效性。下面是按步骤展开的解释：\n",
        "\n",
        "### 步骤 1: 准备你的数据集\n",
        "\n",
        "- 从一个类别分布不平衡的数据集开始。例如，在教育数据挖掘中，这可能涉及到预测学生辍学情况，其中辍学生（少数类）的数量远小于继续就读的学生（多数类）的数量。\n",
        "\n",
        "### 步骤 2: 应用重采样方法\n",
        "\n",
        "- **欠采样**：从多数类中随机移除样本，直至多数类和少数类的样本数量匹配。\n",
        "- **过采样**：在少数类中随机复制样本，直至少数类和多数类的样本数量匹配。\n",
        "- **SMOTE**：通过在现有少数类样本之间插值，生成少数类的合成样本。\n",
        "\n",
        "### 步骤 3: 训练分类器\n",
        "\n",
        "- 对所有三个数据集使用常见的分类器。由于其解释性和易用性，逻辑回归、决策树或随机森林是受欢迎的选择。\n",
        "\n",
        "### 步骤 4: 评估模型性能\n",
        "\n",
        "- **精确度（Precision）**：衡量正例预测的准确性。\n",
        "- **召回率（Recall）**：衡量分类器找到所有正样本的能力。\n",
        "- **F1分数（F1-score）**：提供精确度和召回率之间的平衡。\n",
        "- **AUC（Area Under Curve）**：表示模型区分不同类别的可能性。\n",
        "\n",
        "通过比较这些方法的性能指标，我们可以评估它们在处理特定问题上的有效性。例如，在教育数据挖掘的背景下，我们可能特别关注召回率，因为识别潜在的辍学学生比错误地将持续就读的学生归为辍学更为重要。同时，F1分数和AUC也是评价模型整体性能的重要指标，因为它们综合了模型的精确度和召回率，以及模型区分不同类别的能力。\n",
        "\n",
        "实证比较这些方法时，重要的是要注意数据集的具体情况和应用场景的需求，因为不同的场景可能需要不同的平衡点。例如，在一些情况下，保持较高的召回率可能比保持较高的精确度更为重要，反之亦然。此外，虽然SMOTE和其他过采样技术可以有效地增加少数类的样本数量，但也可能导致过拟合，因此需要谨慎使用。"
      ],
      "metadata": {
        "id": "ZOcEPt_ze3ne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Implications in Educational Data Mining\n",
        "\n",
        "在处理不平衡数据集时，我们常常面临一个挑战：如何平衡类别以提高模型的性能，同时又不损失过多的信息或增加过拟合的风险。欠采样、过采样和SMOTE是三种常用的方法，它们各有优势和劣势。\n",
        "\n",
        "### 欠采样（Undersampling）\n",
        "\n",
        "- **原理**：通过随机移除多数类中的一部分样本来减少多数类的规模，使得类别之间的分布更加平衡。\n",
        "  \n",
        "- **优势**：简单且易于实施，可以快速减少数据集的大小，从而减少计算成本。\n",
        "\n",
        "- **劣势**：\n",
        "  - 可能会导致重要信息的丢失，因为一些多数类的样本可能包含对模型训练有用的信息，而随机删除可能会忽略这些信息。\n",
        "  - 在未见数据上的表现可能会降低，因为模型未能充分学习多数类的特征。\n",
        "\n",
        "### 过采样（Oversampling）\n",
        "\n",
        "- **原理**：通过复制少数类样本或添加少数类样本的轻微变化副本来增加少数类的规模，从而达到类别平衡。\n",
        "\n",
        "- **优势**：帮助模型更好地学习并识别少数类，可能提高模型对少数类的检测能力。\n",
        "\n",
        "- **劣势**：\n",
        "  - 可能增加过拟合的风险，因为重复的少数类样本可能会使模型过于关注这些重复的特征，而不是学习更广泛的特征。\n",
        "  - 不增加新的信息，只是通过重复现有样本来增加少数类的数量。\n",
        "\n",
        "### SMOTE（合成少数过采样技术）\n",
        "\n",
        "- **原理**：通过在少数类样本之间插值来生成新的合成样本，旨在增加少数类的样本数量并提供新的信息。\n",
        "\n",
        "- **优势**：\n",
        "  - 提供了通过生成新样本来增加少数类样本数量的方法，这些新样本是现有样本的变体，从而为模型训练引入了新的信息。\n",
        "  - 有助于改善模型的泛化能力，因为它通过添加新的、但与现有样本相关的样本来增强数据集，而不仅仅是重复现有的样本。\n",
        "\n",
        "- **劣势**：\n",
        "  - 虽然比简单的过采样风险低，但生成的合成样本仍然可能引入一些噪声，特别是在样本分布复杂或有重叠的情况下。\n",
        "  - 计算成本相对较高，因为需要在现有样本之间进行插值计算来生成新的样本。\n",
        "\n",
        "总的来说，每种方法都有其适用的场景，选择合适的方法需要考虑数据的特点、模型的需求以及实际应用场景。在实践中，可能还需要结合多种技术，或尝试更先进的方法（如基于聚类的过采样方法），以最佳地解决不平衡数据问题。"
      ],
      "metadata": {
        "id": "TAJf1eYNbSv_"
      }
    }
  ]
}